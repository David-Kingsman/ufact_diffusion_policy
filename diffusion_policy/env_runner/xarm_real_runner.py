import threading
import time
import os
import os.path as osp
import numpy as np
import torch
import tqdm
from loguru import logger
from typing import Dict, Tuple, Union, Optional, Any, List  
import transforms3d as t3d
from omegaconf import DictConfig, ListConfig
from copy import deepcopy

from diffusion_policy.policy.diffusion_unet_image_policy import DiffusionUnetImagePolicy
from diffusion_policy.common.pytorch_util import dict_apply
from diffusion_policy.env_runner.base_image_runner import BaseImageRunner

# æ·»åŠ XARMç›¸å…³çš„å¯¼å…¥
try:
    # å‡è®¾ä½ æœ‰XARMçš„Python SDK
    from xarm.wrapper import XArmAPI
    XARM_AVAILABLE = True
except ImportError:
    logger.warning("XARM SDK not available, using simulation mode")
    XARM_AVAILABLE = False

import cv2
cv2.setNumThreads(4)

class XarmRealRunner(BaseImageRunner):
    """
    å®Œæ•´çš„XARMçœŸå®æœºå™¨äººè¯„ä¼°å™¨
    æ”¯æŒçœŸå®æœºå™¨äººæ§åˆ¶ã€ç›¸æœºé‡‡é›†ã€åŠ¨ä½œæ¨ç†
    """
    
    def __init__(self,
                 output_dir: str,
                 shape_meta: DictConfig,
                 # XARMé…ç½®
                 xarm_ip: str = "192.168.1.235",  # XARMæœºå™¨äººIP
                 camera_indices: List[int] = [0],  # ç›¸æœºè®¾å¤‡ç´¢å¼•
                 # è¯„ä¼°å‚æ•°
                 eval_episodes: int = 10,
                 max_duration_time: float = 30.0,
                 max_steps: int = 400,
                 # æ§åˆ¶å‚æ•°
                 control_fps: float = 20.0,
                 inference_fps: float = 10.0,
                 n_obs_steps: int = 2,
                 n_action_steps: int = 8,
                 # åŠ¨ä½œå‚æ•°
                 action_horizon: int = 16,
                 use_relative_action: bool = False,
                 # å®‰å…¨å‚æ•°
                 position_limits: List[List[float]] = None,
                 velocity_limit: float = 100.0,  # mm/s
                 # å¯è§†åŒ–
                 enable_video_recording: bool = True,
                 save_obs: bool = True,
                 **kwargs):
        
        super().__init__(output_dir)
        
        self.shape_meta = dict(shape_meta)
        self.eval_episodes = eval_episodes
        self.max_duration_time = max_duration_time
        self.max_steps = max_steps
        
        # æ§åˆ¶é¢‘ç‡
        self.control_fps = control_fps
        self.inference_fps = inference_fps
        self.control_interval = 1.0 / control_fps
        self.inference_interval = 1.0 / inference_fps
        assert control_fps % inference_fps == 0
        
        # è§‚æµ‹å’ŒåŠ¨ä½œå‚æ•°
        self.n_obs_steps = n_obs_steps
        self.n_action_steps = n_action_steps
        self.action_horizon = action_horizon
        self.use_relative_action = use_relative_action
        
        # å®‰å…¨é™åˆ¶
        self.position_limits = position_limits or [
            [200, -400, 100],   # xyz min (mm)
            [700, 400, 600]     # xyz max (mm)  
        ]
        self.velocity_limit = velocity_limit
        
        # å¯è§†åŒ–
        self.enable_video_recording = enable_video_recording
        self.save_obs = save_obs
        self.video_dir = osp.join(output_dir, 'videos')
        self.obs_dir = osp.join(output_dir, 'observations')
        os.makedirs(self.video_dir, exist_ok=True)
        os.makedirs(self.obs_dir, exist_ok=True)
        
        # åˆå§‹åŒ–XARM
        self.xarm_ip = xarm_ip
        self.xarm = None
        self.cameras = []
        self.camera_indices = camera_indices
        
        # çº¿ç¨‹æ§åˆ¶
        self.stop_event = threading.Event()
        self.action_queue = []
        self.action_lock = threading.Lock()
        
        # åˆå§‹åŒ–ç¡¬ä»¶
        self._init_xarm()
        self._init_cameras()
        
        logger.info(f"XarmRealRunner initialized: {eval_episodes} episodes, "
                   f"control_fps={control_fps}, inference_fps={inference_fps}")
    
    def _init_xarm(self):
        """åˆå§‹åŒ–XARMæœºå™¨äºº"""
        if not XARM_AVAILABLE:
            logger.warning("XARM SDK not available, skipping robot initialization")
            return
            
        try:
            self.xarm = XArmAPI(self.xarm_ip)
            self.xarm.connect()
            
            # ä½¿èƒ½æœºå™¨äºº
            self.xarm.motion_enable(enable=True)
            self.xarm.set_mode(0)  # ä½ç½®æ§åˆ¶æ¨¡å¼
            self.xarm.set_state(state=0)  # è¿åŠ¨çŠ¶æ€
            
            # è®¾ç½®å®‰å…¨å‚æ•°
            self.xarm.set_tcp_maxacc(1000)  # æœ€å¤§åŠ é€Ÿåº¦
            self.xarm.set_tcp_jerk(10000)   # æœ€å¤§jerk
            
            logger.info(f"XARM connected successfully: {self.xarm_ip}")
            
        except Exception as e:
            logger.error(f"Failed to initialize XARM: {e}")
            self.xarm = None
    
    def _init_cameras(self):
        """åˆå§‹åŒ–ç›¸æœº"""
        for idx in self.camera_indices:
            try:
                cap = cv2.VideoCapture(idx)
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, 224)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 224)
                cap.set(cv2.CAP_PROP_FPS, 30)
                
                if cap.isOpened():
                    self.cameras.append(cap)
                    logger.info(f"Camera {idx} initialized successfully")
                else:
                    logger.warning(f"Failed to open camera {idx}")
                    
            except Exception as e:
                logger.error(f"Error initializing camera {idx}: {e}")
    
    def _get_robot_state(self) -> Dict[str, np.ndarray]:
        """è·å–æœºå™¨äººå½“å‰çŠ¶æ€"""
        if self.xarm is None:
            # æ¨¡æ‹ŸçŠ¶æ€
            return {
                'robot_eef_pose': np.random.randn(6),  # xyz + rpy
                'robot_joint': np.random.randn(7),     # 7ä¸ªå…³èŠ‚è§’åº¦
                'robot_joint_vel': np.random.randn(7), # 7ä¸ªå…³èŠ‚é€Ÿåº¦
                'gripper': np.random.rand(1) * 850     # å¤¹çˆªå¼€åº¦
            }
        
        try:
            # è·å–TCPä½å§¿
            ret, tcp_pose = self.xarm.get_position()
            if ret != 0:
                tcp_pose = [0, 0, 0, 0, 0, 0]
            
            # è·å–å…³èŠ‚è§’åº¦
            ret, joint_angles = self.xarm.get_servo_angle()
            if ret != 0:
                joint_angles = [0] * 7
            
            # è·å–å…³èŠ‚é€Ÿåº¦ (å¦‚æœæ”¯æŒ)
            joint_velocities = [0] * 7  # XARMå¯èƒ½ä¸ç›´æ¥æä¾›é€Ÿåº¦
            
            # è·å–å¤¹çˆªçŠ¶æ€
            ret, gripper_pos = self.xarm.get_gripper_position()
            if ret != 0:
                gripper_pos = 0
            
            return {
                'robot_eef_pose': np.array(tcp_pose, dtype=np.float32),
                'robot_joint': np.array(joint_angles, dtype=np.float32) * np.pi / 180,  # è½¬æ¢ä¸ºå¼§åº¦
                'robot_joint_vel': np.array(joint_velocities, dtype=np.float32),
                'gripper': np.array([gripper_pos], dtype=np.float32)
            }
            
        except Exception as e:
            logger.error(f"Error getting robot state: {e}")
            return self._get_robot_state()  # è¿”å›æ¨¡æ‹ŸçŠ¶æ€
    
    def _capture_images(self) -> Dict[str, np.ndarray]:
        """é‡‡é›†ç›¸æœºå›¾åƒ"""
        images = {}
        
        for i, cap in enumerate(self.cameras):
            try:
                ret, frame = cap.read()
                if ret:
                    # è°ƒæ•´å°ºå¯¸å¹¶å½’ä¸€åŒ–
                    frame = cv2.resize(frame, (224, 224))
                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    frame = frame.astype(np.float32) / 255.0
                    frame = frame.transpose(2, 0, 1)  # HWC -> CHW
                    
                    # ä½¿ç”¨é…ç½®ä¸­çš„ç›¸æœºåç§°
                    if i == 0:
                        images['agentview_image'] = frame
                    else:
                        images[f'camera_{i}'] = frame
                else:
                    logger.warning(f"Failed to capture from camera {i}")
                    # ä½¿ç”¨é»‘è‰²å›¾åƒä½œä¸ºfallback
                    images['agentview_image'] = np.zeros((3, 224, 224), dtype=np.float32)
                    
            except Exception as e:
                logger.error(f"Error capturing from camera {i}: {e}")
                images['agentview_image'] = np.zeros((3, 224, 224), dtype=np.float32)
        
        return images
    
    def _get_observation(self) -> Dict[str, np.ndarray]:
        """è·å–å®Œæ•´è§‚æµ‹"""
        # è·å–æœºå™¨äººçŠ¶æ€
        robot_state = self._get_robot_state()
        
        # è·å–å›¾åƒ
        images = self._capture_images()
        
        # åˆå¹¶è§‚æµ‹
        obs = {**robot_state, **images}
        return obs
    
    def _execute_action(self, action: np.ndarray):
        """æ‰§è¡ŒåŠ¨ä½œ"""
        if self.xarm is None:
            logger.debug(f"Simulated action: {action}")
            time.sleep(0.01)  # æ¨¡æ‹Ÿæ‰§è¡Œæ—¶é—´
            return
        
        try:
            # è§£æåŠ¨ä½œ (å‡è®¾æ˜¯7ç»´: xyz + rpy + gripper)
            if len(action) >= 7:
                xyz = action[:3] * 1000  # è½¬æ¢ä¸ºmm
                rpy = action[3:6] * 180 / np.pi  # è½¬æ¢ä¸ºåº¦
                gripper = action[6] if len(action) > 6 else 0
                
                # å®‰å…¨æ£€æŸ¥
                xyz = np.clip(xyz, self.position_limits[0], self.position_limits[1])
                
                # æ‰§è¡ŒTCPè¿åŠ¨
                pose = list(xyz) + list(rpy)
                ret = self.xarm.set_position(*pose, 
                                           speed=self.velocity_limit, 
                                           wait=False)
                
                if ret != 0:
                    logger.warning(f"XARM motion command failed: {ret}")
                
                # æ‰§è¡Œå¤¹çˆªåŠ¨ä½œ
                if len(action) > 6:
                    gripper_pos = np.clip(gripper, 0, 850)
                    self.xarm.set_gripper_position(gripper_pos, wait=False)
                    
        except Exception as e:
            logger.error(f"Error executing action: {e}")
    
    def _action_control_thread(self, policy):
        """åŠ¨ä½œæ§åˆ¶çº¿ç¨‹"""
        step_count = 0
        
        while not self.stop_event.is_set():
            start_time = time.time()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°åŠ¨ä½œ
            with self.action_lock:
                if self.action_queue:
                    action = self.action_queue.pop(0)
                    self._execute_action(action)
            
            # ä¿æŒæ§åˆ¶é¢‘ç‡
            elapsed = time.time() - start_time
            sleep_time = max(0, self.control_interval - elapsed)
            time.sleep(sleep_time)
            step_count += 1
    
    def _collect_observation_sequence(self) -> Dict[str, np.ndarray]:
        """æ”¶é›†è§‚æµ‹åºåˆ—"""
        obs_sequence = []
        
        for _ in range(self.n_obs_steps):
            obs = self._get_observation()
            obs_sequence.append(obs)
            time.sleep(0.1)  # çŸ­æš‚é—´éš”
        
        # è½¬æ¢ä¸ºæ‰¹æ¬¡æ ¼å¼
        batch_obs = {}
        for key in obs_sequence[0].keys():
            values = [obs[key] for obs in obs_sequence]
            batch_obs[key] = np.stack(values, axis=0)
        
        return batch_obs
    
    def run(self, policy: DiffusionUnetImagePolicy) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´è¯„ä¼°"""
        logger.info(f"Starting XARM evaluation with {self.eval_episodes} episodes")
        
        policy.eval()
        device = policy.device
        
        all_episode_results = []
        
        try:
            for episode_idx in range(self.eval_episodes):
                logger.info(f"Episode {episode_idx + 1}/{self.eval_episodes}")
                
                # é‡ç½®ç¯å¢ƒ (æ‰‹åŠ¨æˆ–è‡ªåŠ¨)
                self._reset_episode()
                
                # å¯åŠ¨åŠ¨ä½œæ§åˆ¶çº¿ç¨‹
                self.stop_event.clear()
                self.action_queue = []
                
                action_thread = threading.Thread(
                    target=self._action_control_thread, 
                    args=(policy,), 
                    daemon=True
                )
                action_thread.start()
                
                # è¿è¡Œå•ä¸ªepisode
                episode_result = self._run_episode(policy, device, episode_idx)
                all_episode_results.append(episode_result)
                
                # åœæ­¢æ§åˆ¶çº¿ç¨‹
                self.stop_event.set()
                action_thread.join(timeout=2.0)
                
                logger.info(f"Episode {episode_idx + 1} completed: "
                           f"reward={episode_result['reward']:.3f}, "
                           f"success={episode_result['success']}")
        
        finally:
            self._cleanup()
        
        # è®¡ç®—ç»Ÿè®¡ç»“æœ
        results = self._compute_statistics(all_episode_results)
        logger.info("Evaluation completed!")
        self._log_results(results)
        
        return results
    
    def _reset_episode(self):
        """é‡ç½®episodeç¯å¢ƒ"""
        if self.xarm is not None:
            try:
                # ç§»åŠ¨åˆ°å®‰å…¨ä½ç½®
                self.xarm.set_position(400, 0, 300, 0, 0, 0, speed=100, wait=True)
                # æ‰“å¼€å¤¹çˆª
                self.xarm.set_gripper_position(850, wait=True)
                logger.info("XARM reset to initial position")
            except Exception as e:
                logger.error(f"Error resetting XARM: {e}")
        
        # ç”¨æˆ·ç¡®è®¤
        input("Press Enter when environment is ready...")
    
    def _run_episode(self, policy, device, episode_idx) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªepisode"""
        episode_reward = 0.0
        success = False
        step_count = 0
        
        episode_start_time = time.time()
        last_inference_time = episode_start_time
        
        episode_obs = []
        episode_actions = []
        
        try:
            while step_count < self.max_steps:
                current_time = time.time()
                
                # æ£€æŸ¥æ—¶é—´é™åˆ¶
                if current_time - episode_start_time > self.max_duration_time:
                    logger.info("Episode timeout")
                    break
                
                # æ¨ç†é¢‘ç‡æ§åˆ¶
                if current_time - last_inference_time >= self.inference_interval:
                    # æ”¶é›†è§‚æµ‹
                    obs_dict = self._collect_observation_sequence()
                    
                    # è½¬æ¢ä¸ºtensor
                    obs_tensor = {}
                    for key, value in obs_dict.items():
                        obs_tensor[key] = torch.from_numpy(value).float().unsqueeze(0).to(device)
                    
                    # ç­–ç•¥æ¨ç†
                    with torch.no_grad():
                        action_dict = policy.predict_action(obs_tensor)
                    
                    # æå–åŠ¨ä½œåºåˆ—
                    actions = action_dict['action'][0].cpu().numpy()  # (action_horizon, action_dim)
                    
                    # æ·»åŠ åŠ¨ä½œåˆ°é˜Ÿåˆ—
                    with self.action_lock:
                        # åªå–å‰å‡ ä¸ªåŠ¨ä½œæ­¥
                        for i in range(min(self.n_action_steps, len(actions))):
                            self.action_queue.append(actions[i])
                    
                    # ä¿å­˜æ•°æ®
                    if self.save_obs:
                        episode_obs.append(obs_dict)
                        episode_actions.append(actions)
                    
                    # ç®€å•çš„å¥–åŠ±è®¡ç®— (å¯ä»¥æ ¹æ®ä»»åŠ¡å®šåˆ¶)
                    step_reward = self._compute_reward(obs_dict)
                    episode_reward += step_reward
                    
                    # ç®€å•çš„æˆåŠŸåˆ¤æ–­ (å¯ä»¥æ ¹æ®ä»»åŠ¡å®šåˆ¶)
                    if step_reward > 0.8:
                        success = True
                        break
                    
                    last_inference_time = current_time
                    step_count += 1
                
                time.sleep(0.01)  # çŸ­æš‚ä¼‘çœ 
                
        except KeyboardInterrupt:
            logger.warning("Episode interrupted by user")
        
        # ä¿å­˜episodeæ•°æ®
        if self.save_obs:
            self._save_episode_data(episode_idx, episode_obs, episode_actions)
        
        return {
            'reward': episode_reward,
            'success': success,
            'steps': step_count,
            'duration': time.time() - episode_start_time
        }
    
    def _compute_reward(self, obs_dict: Dict[str, np.ndarray]) -> float:
        """è®¡ç®—å¥–åŠ± (éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡å®šåˆ¶)"""
        # è¿™é‡Œæ˜¯ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹
        # å¯ä»¥åŸºäºä»»åŠ¡å®Œæˆåº¦ã€è·ç¦»ç›®æ ‡çš„è·ç¦»ç­‰è®¡ç®—
        
        # ç¤ºä¾‹: åŸºäºæœ«ç«¯æ‰§è¡Œå™¨ä½ç½®è®¡ç®—å¥–åŠ±
        eef_pose = obs_dict['robot_eef_pose'][-1]  # æœ€æ–°çš„ä½å§¿
        target_position = np.array([0.5, 0.0, 0.3])  # ç¤ºä¾‹ç›®æ ‡ä½ç½®
        
        distance = np.linalg.norm(eef_pose[:3] - target_position)
        reward = max(0, 1.0 - distance)  # è·ç¦»è¶Šè¿‘å¥–åŠ±è¶Šé«˜
        
        return reward
    
    def _save_episode_data(self, episode_idx: int, obs_list: list, action_list: list):
        """ä¿å­˜episodeæ•°æ®"""
        try:
            episode_data = {
                'observations': obs_list,
                'actions': action_list,
                'episode_idx': episode_idx
            }
            
            save_path = osp.join(self.obs_dir, f'episode_{episode_idx}.npz')
            np.savez_compressed(save_path, **episode_data)
            logger.debug(f"Episode data saved to {save_path}")
            
        except Exception as e:
            logger.error(f"Error saving episode data: {e}")
    
    def _compute_statistics(self, episode_results: list) -> Dict[str, float]:
        """è®¡ç®—ç»Ÿè®¡ç»“æœ"""
        if not episode_results:
            return {}
        
        rewards = [r['reward'] for r in episode_results]
        successes = [r['success'] for r in episode_results]
        durations = [r['duration'] for r in episode_results]
        
        return {
            'train_mean_score': np.mean(rewards),
            'train_std_score': np.std(rewards),
            'test_mean_score': np.mean(rewards),  # åŒè®­ç»ƒé›†
            'test_std_score': np.std(rewards),
            'train_success_rate': np.mean(successes),
            'test_success_rate': np.mean(successes),
            'mean_duration': np.mean(durations),
            'total_episodes': len(episode_results)
        }
    
    def _log_results(self, results: Dict[str, float]):
        """è®°å½•ç»“æœ"""
        logger.info("\nğŸ“Š XARM Evaluation Results:")
        for key, value in results.items():
            if isinstance(value, float):
                logger.info(f"  {key}: {value:.3f}")
            else:
                logger.info(f"  {key}: {value}")
    
    def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        # åœæ­¢çº¿ç¨‹
        self.stop_event.set()
        
        # å…³é—­ç›¸æœº
        for cap in self.cameras:
            cap.release()
        
        # æ–­å¼€XARMè¿æ¥
        if self.xarm is not None:
            try:
                self.xarm.disconnect()
                logger.info("XARM disconnected")
            except Exception as e:
                logger.error(f"Error disconnecting XARM: {e}")
